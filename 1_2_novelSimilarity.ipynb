{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pBi5eeO8z_2C"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "a8TDekIUEeSM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import shutil\n",
        "from google.colab import output\n",
        "import numpy as np\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import DataFrameWriter\n",
        "import pyspark.sql.functions as func\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, Word2VecModel, CountVectorizer, HashingTF, IDF\n",
        "from pyspark.ml.linalg import SparseVector, DenseVector\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.clustering import LDA, LDAModel\n"
      ],
      "metadata": {
        "id": "r7uJSIc9W3fE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1xWfOl7SXQVwt0jZGAvIuQ16aEOgA5UOF' -O \"Adventures_of_Sherlock_Holmes.txt\"\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1MIJHD5xJP2ZNJhGYUkOZQl7e7FmKPJi1' -O 'Alice_in_wornderland.txt'\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1KlPWjw8IlP5QswnPqso_LabNiqOXm2uC' -O 'Dracula_bromstoker.txt'\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1358EsgbTUx8OjrlvuvQcsU2Bv8ead82z' -O 'Jane_Eyre.txt'\n",
        "\n",
        "source_dir = '/content/'\n",
        "target_dir = '/content/books/'\n",
        "os.mkdir(target_dir)\n",
        "files = os.listdir(source_dir)\n",
        "\n",
        "for file in files:\n",
        "    source = os.path.join(source_dir, file)\n",
        "    target = os.path.join(target_dir, file)\n",
        "    if file.endswith('.txt') and file != 'janeAustine.txt':\n",
        "        shutil.move(source, target)\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "5PhDljIPW3tf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparkNLP = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sparkNLP.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "sparkNLP\n",
        "sc = SparkContext.getOrCreate(sparkNLP.conf)\n",
        "\n",
        "# textRdd = sparkNlp.sparkContext.wholeTextFiles(\"/content/books/*\")"
      ],
      "metadata": {
        "id": "9K-8VlkqW3mR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.types import FloatType\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "# def cosine_similarity(vec1, vec2):\n",
        "#     return vec1.dot(vec2) / (Vectors.norm(vec1, 1) * Vectors.norm(vec2, 1))\n",
        "\n",
        "# cosine_similarity_udf = udf(cosine_similarity, FloatType())\n",
        "\n",
        "data = [('Dracula_bromstoker.txt', open('/content/books/Dracula_bromstoker.txt', 'r').read()),\n",
        "        ('Adventures_of_Sherlock_Holmes.txt', open('/content/books/Adventures_of_Sherlock_Holmes.txt', 'r').read()),\n",
        "        ('Alice_in_wornderland.txt', open('/content/books/Alice_in_wornderland.txt', 'r').read()),\n",
        "        ('Jane_Eyre.txt', open('/content/books/Jane_Eyre.txt', 'r').read())]\n",
        "\n",
        "df = sparkNLP.createDataFrame(data, ['book', 'content'])\n",
        "# tokenizer = Tokenizer(inputCol='content', outputCol='words')\n",
        "# wordsData = tokenizer.transform(df)\n",
        "\n",
        "# SWordFilter = StopWordsRemover(inputCol='words', outputCol='SWRemoved', caseSensitive=False)\n",
        "# processedData = SWordFilter.transform(wordsData)\n",
        "\n",
        "# hashingTF = HashingTF(inputCol='SWRemoved', outputCol='rawFeatures')\n",
        "# featurizedData = hashingTF.transform(processedData)\n",
        "\n",
        "\n",
        "# pairs = featurizedData.alias(\"df1\").crossJoin(featurizedData.alias(\"df2\"))\n",
        "\n",
        "# result = pairs.withColumn(\"similarity\", cosine_similarity_udf(func.col(\"df1.rawFeatures\"), func.col(\"df2.rawFeatures\")))\n",
        "\n",
        "# result.select(\"df1.files\", \"df2.files\", \"similarity\").show()"
      ],
      "metadata": {
        "id": "PLbPlxqolrR9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euBOCHQErCUH",
        "outputId": "ea35629b-b8f9-4c88-a614-04d5d6dadab2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|                book|             content|\n",
            "+--------------------+--------------------+\n",
            "|Dracula_bromstoke...|The Project Guten...|\n",
            "|Adventures_of_She...|\n",
            "Project Gutenber...|\n",
            "|Alice_in_wornderl...|The Project Guten...|\n",
            "|       Jane_Eyre.txt|The Project Guten...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "def text_similarity(df, text1, text2):\n",
        "    tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"words\")\n",
        "    wordsData = tokenizer.transform(df)\n",
        "\n",
        "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "    featurizedData = hashingTF.transform(wordsData)\n",
        "\n",
        "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "    idfModel = idf.fit(featurizedData)\n",
        "    rescaledData = idfModel.transform(featurizedData)\n",
        "\n",
        "    text1_features = rescaledData.filter(col('book') == text1).select('features').first()[0]\n",
        "    text2_features = rescaledData.filter(col('book') == text2).select('features').first()[0]\n",
        "\n",
        "    cosine_similarity = float(text1_features.dot(text2_features) / (text1_features.norm(2) * text2_features.norm(2)))\n",
        "\n",
        "    print(f\"Cosine similarity between {text1} and {text2}: {round(cosine_similarity * 100, 2)}\")\n",
        "\n",
        "\n",
        "for i in range(len(data)):\n",
        "    for j in range(i, len(data)):\n",
        "        text_similarity(df, data[i][0], data[j][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqXt7IOB0ej8",
        "outputId": "74421612-05b1-415b-a443-ce8761fcf80a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between Dracula_bromstoker.txt and Dracula_bromstoker.txt: 100.0\n",
            "Cosine similarity between Dracula_bromstoker.txt and Adventures_of_Sherlock_Holmes.txt: 33.46\n",
            "Cosine similarity between Dracula_bromstoker.txt and Alice_in_wornderland.txt: 1.74\n",
            "Cosine similarity between Dracula_bromstoker.txt and Jane_Eyre.txt: 41.36\n",
            "Cosine similarity between Adventures_of_Sherlock_Holmes.txt and Adventures_of_Sherlock_Holmes.txt: 100.0\n",
            "Cosine similarity between Adventures_of_Sherlock_Holmes.txt and Alice_in_wornderland.txt: 2.97\n",
            "Cosine similarity between Adventures_of_Sherlock_Holmes.txt and Jane_Eyre.txt: 64.74\n",
            "Cosine similarity between Alice_in_wornderland.txt and Alice_in_wornderland.txt: 100.0\n",
            "Cosine similarity between Alice_in_wornderland.txt and Jane_Eyre.txt: 5.31\n",
            "Cosine similarity between Jane_Eyre.txt and Jane_Eyre.txt: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# textRdd.collect()"
      ],
      "metadata": {
        "id": "i5as-F1neKxl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# textDf = textRdd.toDF([\"file\", \"text\"])\n",
        "\n",
        "# tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "# wordsData = tokenizer.transform(textDf)\n",
        "\n",
        "# stopWordsFilter = StopWordsRemover(inputCol='words', outputCol=\"SWRemoved\", caseSensitive=False)\n",
        "# wordsDataClean = stopWordsFilter.transform(wordsData)\n",
        "\n",
        "# hashingTF = HashingTF(inputCol=\"SWRemoved\", outputCol=\"raw_features\")\n",
        "# featurizedData = hashingTF.transform(wordsDataClean)\n",
        "\n",
        "# idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "# idfModel = idf.fit(featurizedData)\n",
        "# tfidfData = idfModel.transform(featurizedData)\n"
      ],
      "metadata": {
        "id": "s7iQRTDLeWnR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidfData"
      ],
      "metadata": {
        "id": "rjnNlJnQekZK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lda = LDA(k=2, maxIter=10, featuresCol=\"features\")\n",
        "# model = lda.fit(tfidfData)\n",
        "\n",
        "# transformed = model.transform(tfidfData)"
      ],
      "metadata": {
        "id": "i35ZMbeATt26"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# topics = model.describeTopics(2)\n",
        "# topics"
      ],
      "metadata": {
        "id": "sN_3HCMMcQmE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed"
      ],
      "metadata": {
        "id": "xDrmR8PZ1o4x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql.functions import udf\n",
        "# from pyspark.sql.types import DoubleType\n",
        "# from scipy.spatial.distance import cosine\n",
        "\n",
        "\n",
        "# def cosine_similarity(x, y):\n",
        "#     return float(1 - cosine(x, y))\n",
        "\n",
        "# cosineSimilarityUdf = udf(cosine_similarity, DoubleType())\n",
        "\n",
        "# dfCross = transformed.crossJoin(transformed.withColumnRenamed(\"topicDistribution\", \"topicDistribution2\"))\n",
        "# dfSimilarity = dfCross.withColumn(\"similarity\", cosineSimilarityUdf(dfCross[\"topicDistribution\"], dfCross[\"topicDistribution2\"]))"
      ],
      "metadata": {
        "id": "s3w0uCN9IoOH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dfSimilarity.show()"
      ],
      "metadata": {
        "id": "IISydMSNOn_J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparkNLP.stop()"
      ],
      "metadata": {
        "id": "tDeT8TE2RULw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4vlYy-k1nqU"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}